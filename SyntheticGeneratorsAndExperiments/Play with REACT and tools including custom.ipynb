{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRYSu48huSUW",
    "outputId": "58f7189c-d60a-4871-e83b-d7150246839d",
    "tags": []
   },
   "source": [
    "#!pip -q install langchain tiktoken\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.utilities import WikipediaAPIWrapper"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tooltavily = TavilySearchResults()\n",
    "tooltavily.invoke({\"query\": \"SMart home systems testing with rares Cristea?\"})\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia.run('Steaua Bucuresti')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsE8T9csScMN"
   },
   "source": [
    "## REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cCOKsQ9tSdqM",
    "tags": []
   },
   "source": [
    "from langchain.utilities import PythonREPL"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-eh-rd7sSgPi",
    "tags": []
   },
   "source": [
    "python_repl = PythonREPL()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zbQF6osMSjFf",
    "outputId": "fab3d709-13dc-4edc-d241-2550e31576f5",
    "tags": []
   },
   "source": [
    "python_repl.run(\"print(17*2)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo3QlrUB3iRv",
    "tags": []
   },
   "source": [
    "## Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oLqOaMQq3kpB",
    "tags": []
   },
   "source": [
    "#from langchain import OpenAI\n",
    "# llm = OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "##%%\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, TextStreamer\n",
    "import json\n",
    "import torch\n",
    "import textwrap\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    \n",
    "\n",
    "model_name = \"meta-llama/Llama-2-13b-chat-hf\" # \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          token=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             token=True,\n",
    "                                             #  load_in_8bit=True,\n",
    "                                             load_in_4bit=True,\n",
    "                                             )\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens=4096,\n",
    "                do_sample=True,\n",
    "                temperature=0.1,\n",
    "                top_p=0.95,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                streamer=streamer,\n",
    "                )\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_1T2Z_mZ4vHc",
    "tags": []
   },
   "source": [
    "python_tool = Tool(\n",
    "        name = \"python repl\",\n",
    "        func=python_repl.run,\n",
    "        description=\"useful for when you need to use python to answer a question. You should input python code\"\n",
    "    )\n",
    "\n",
    "\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"Useful for when you need to look up a topic, country or person on wikipedia\"\n",
    ")\n",
    "\n",
    "tooltavily_tool = Tool(\n",
    "    name='tavily Search',\n",
    "    func= tooltavily.run,\n",
    "    description=\"Useful for when you need to do a search on the internet to find information that another tool can't find. be specific with your input.\"\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "def random_num(input=\"\"):\n",
    "    return random.randint(0,5)\n",
    "def meaning_of_life(input=\"\"):\n",
    "    return 'The meaning of life is 42 if rounded but is actually 42.17658'\n",
    "\n",
    "random_tool = Tool(\n",
    "    name='Random number',\n",
    "    func= random_num,\n",
    "    description=\"Useful for when you need to get a random number. input should be 'random'\"\n",
    ")\n",
    "\n",
    "life_tool = Tool(\n",
    "    name='Meaning of Life',\n",
    "    func= meaning_of_life,\n",
    "    description=\"Useful for when you need to answer questions about the meaning of life. input should be MOL \"\n",
    ")\n",
    "\n",
    "\n",
    "tools = [python_tool, wikipedia_tool, tooltavily_tool, random_tool, life_tool]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q66NZx7UFNff"
   },
   "source": [
    "## Using the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5e4eb28c",
    "tags": []
   },
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "# conversational agent memory\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=3,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "\n",
    "# create our agent\n",
    "\"\"\"\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\", \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "source": [
    "zero_shot_agent(\"Can you give me a random number?\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "IrFei5ys5Wgk",
    "outputId": "242cfed3-365f-40f8-dac6-742497ccc241",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run(\"What was the contribution of Rares Cristea to the Smart Home fuzzing and testing?\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "CABxVBKL5tX7",
    "outputId": "7a944e56-d4d0-470d-b02c-6a0f44cfe812",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run(\"What is 17*6?\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mObTFFLy6Pdo",
    "outputId": "c2593a7b-1d92-4320-b58e-7265730ec528",
    "tags": []
   },
   "source": [
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "9_gCVreU6ZI8",
    "outputId": "6c59a289-4c7f-4ad7-9cdf-b12d3727bf08",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run(\"Tell me about a DDoS\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "U7iD-DoidwYZ",
    "outputId": "b0dec6b7-e3b3-48b7-99b5-3961ab3208e5",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run(\"Tell me about research in Romania\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "CUALszCF7r3j",
    "outputId": "971d8aa4-b056-47bd-868a-92276c365c59",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run('Is 11 a prime number?')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "2oKDiMWhe8Dk",
    "outputId": "23a64680-0f07-4f7e-c3fa-3f45d4131554",
    "tags": []
   },
   "source": [
    "zero_shot_agent.run('Write a function to check if 11 a prime number and test it')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0CkeXQnfMxq"
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
