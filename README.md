# CyberGuardian chatbot

## Model loading and usage 
* Step 1: Check our huggingface repository and download the model
https://huggingface.co/datasets/unibuc-cs/CyberGuardianDataset

* Step 2: Use Ollama or Lama.cpp to do local inference of the model, indepedently of the architecture you run on (e.g., you can use MacOS, CPU only, GPUs, etc.).

* Step 3: Install the UI/requirements.txt packages to run the project.

* Step 4: While the UI interface is currently built with Streamlit library, use run MainPage.py to start.
   - Check our video demos, create a profile, and test your skills.
   - Note that it by default it will run our demo in the presentations.

## TODO: 
 - Final paper ICSOFT cite 
 - Upload documentation folder with demos and paper, presentations.

Acknowledgements: This research was supported by European Unionâ€™s Horizon Europe research and innovation programme under grant agreement no. 101070455, [project DYNABIC](https://dynabic.eu), where we use the code for the Chat4Operator component.

